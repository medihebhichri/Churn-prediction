# -*- coding: utf-8 -*-
"""machine_learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l1XUHvLH5POwaD5sp-re23qLEvW5eUw3
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# charger les deux dataset
file_path = '/content/churn-bigml-20.csv'
data = pd.read_csv(file_path)

file_path1 = '/content/churn-bigml-80.csv'
data_testing = pd.read_csv(file_path)

"""AFFICHER DATA TRAINING"""

print(data.head())

"""AFFICHER DATA TESTING"""

print(data_testing.head())

print(data.describe())

print(data_testing.describe())

colonnes = data.columns.tolist()
print(colonnes)

df = pd.DataFrame(data)
features = df.drop('Churn', axis=1)  # Données de caractéristiques
target = df['Churn']
print("Features (X):")
print(features.head())
print("\nTarget (y):")
print(target.head())

"""CONVERTION DATA TRAINING"""

original = data.copy()


binary_columns = original.columns[original.apply(lambda col: col.dropna().isin([0, 1]).all())]


categorical_columns = original.select_dtypes(include=['object', 'category']).columns
print("Colonnes catégoriques :\n")
display(categorical_columns)


integer_columns = original.select_dtypes(include=['int', 'float']).columns
print("Colonnes numériques :\n")
display(integer_columns)

# Combiner les trois ensembles de colonnes
combined_columns = binary_columns.union(categorical_columns).union(integer_columns)

# Exclure la colonne 'Churn' si elle est présente
if 'Churn' in combined_columns:
    combined_columns = combined_columns.drop('Churn')

# Extraire les colonnes sélectionnées
combined_data = original[combined_columns]

# Afficher les colonnes combinées sans 'Churn'
print("Colonnes combinées sans 'Churn' :\n")
display(combined_data)

from sklearn.preprocessing import LabelEncoder

# Identifier les colonnes catégoriques (sans inclure 'Churn' si déjà dans ce type)
categorical_columns = data.select_dtypes(include=['object', 'category']).columns

# Initialiser un encodeur
label_encoder = LabelEncoder()

# Convertir chaque colonne catégorique
for col in categorical_columns:
    data[col] = label_encoder.fit_transform(data[col])

# Convertir la colonne 'Churn' en binaire (0 ou 1)
if data['Churn'].dtype == 'bool' or data['Churn'].nunique() == 2:
    data['Churn'] = data['Churn'].astype(int)
else:
    # Si Churn contient des valeurs textuelles comme "Yes"/"No"
    data['Churn'] = label_encoder.fit_transform(data['Churn'])

# Afficher un aperçu du dataset après conversion
print(data.dtypes)
print(data.head())

df = pd.DataFrame(data)
features = df.drop('Churn', axis=1)  # Données de caractéristiques
target = df['Churn']
print("Features (X):")
print(features.head())
print("\nTarget (y):")
print(target.head())
print(type(target))

"""TESTER LA CORRELATION"""

import seaborn as sns
import matplotlib.pyplot as plt

# Compute the correlation matrix
corr_matrix = data.corr()

# Visualize the correlations with a heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', vmin=-1, vmax=1)
plt.title("Correlation Heatmap")
plt.show()

###trainning featues
from sklearn.preprocessing import LabelEncoder

# Identifier les colonnes catégoriques (sans inclure 'Churn' si déjà dans ce type)
categorical_columns = data.select_dtypes(include=['object', 'category']).columns

# Initialiser un encodeur
label_encoder = LabelEncoder()

# Convertir chaque colonne catégorique
for col in categorical_columns:
    data[col] = label_encoder.fit_transform(data[col])

# Convertir la colonne 'Churn' en binaire (0 ou 1)
if data['Churn'].dtype == 'bool' or data['Churn'].nunique() == 2:
    data['Churn'] = data['Churn'].astype(int)
else:
    # Si Churn contient des valeurs textuelles comme "Yes"/"No"
    data['Churn'] = label_encoder.fit_transform(data['Churn'])

# Afficher un aperçu du dataset après conversion
print(data.head())
print(data.dtypes)

df = pd.DataFrame(data)
features = df.drop('Churn', axis=1)  # Données de caractéristiques
target = df['Churn']
print("Features (X):")
print(features.head())
print("\nTarget (y):")
print(target.head())

from sklearn.feature_selection import SelectKBest, chi2


X = data.drop(columns=['Churn'])
y = data['Churn']  # La cible


chi2_selector = SelectKBest(chi2, k='all')
chi2_selector.fit(X, y)

# Obtenir les scores et p-values
scores = chi2_selector.scores_
p_values = chi2_selector.pvalues_

# Créer un DataFrame des résultats
results_df = pd.DataFrame({
    'Feature': X.columns,
    'Chi2_Score': scores,
    'p_value': p_values
})

# Filtrer les caractéristiques avec une p-value significative (< 0.05)
significant_features = results_df[results_df['p_value'] < 0.05]

# Afficher les résultats
print("Caractéristiques sélectionnées avec p-value < 0.05 :")
print(significant_features)

#testing features

from sklearn.preprocessing import LabelEncoder

# Identifier les colonnes catégoriques (sans inclure 'Churn' si déjà dans ce type)
categorical_columns = data_testing.select_dtypes(include=['object', 'category']).columns

# Initialiser un encodeur
label_encoder = LabelEncoder()

# Convertir chaque colonne catégorique
for col in categorical_columns:
    data_testing[col] = label_encoder.fit_transform(data_testing[col])

# Convertir la colonne 'Churn' en binaire (0 ou 1)
if data_testing['Churn'].dtype == 'bool' or data_testing['Churn'].nunique() == 2:
    data_testing['Churn'] = data_testing['Churn'].astype(int)
else:
    # Si Churn contient des valeurs textuelles comme "Yes"/"No"
    data_testing['Churn'] = label_encoder.fit_transform(data_testing['Churn'])

# Afficher un aperçu du dataset après conversion
print(data_testing.head())
print(data_testing.dtypes)

df_testing = pd.DataFrame(data_testing)
features_testing = df_testing.drop('Churn', axis=1)  # Données de caractéristiques
target_testing = df_testing['Churn']
print("Features (X):")
print(features_testing.head())
print("\nTarget (y):")
print(target_testing.head())

"""OUTLIERS"""

# Sélectionner uniquement les colonnes numériques
X_numeric = X.select_dtypes(include=['float64', 'int64'])

# Calculer les quartiles et l'IQR
Q1 = X_numeric.quantile(0.25)
Q3 = X_numeric.quantile(0.75)
IQR = Q3 - Q1

# Définir les bornes inférieure et supérieure pour chaque caractéristique
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Identifier les outliers
outliers = ((X_numeric < lower_bound) | (X_numeric > upper_bound)).sum()

# Afficher le nombre d'outliers par caractéristique
print(outliers)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6))
sns.boxplot(data=X)
plt.title("Boxplot des caractéristiques")
plt.show()

"""FEATURE VISUALISATION"""

import matplotlib.pyplot as plt
import seaborn as sns

# Trier par score Chi2 et sélectionner les 5 meilleures caractéristiques
best_features = results_df.sort_values(by='Chi2_Score', ascending=False).head(5)['Feature']

# Afficher les courbes pour ces 5 meilleures caractéristiques
for feature in best_features:
    plt.figure(figsize=(8, 5))

    # Vérifier si la caractéristique est catégorielle ou numérique pour choisir le bon type de graphique
    if data[feature].dtype == 'object' or data[feature].nunique() < 20:  # Si catégorielle
        sns.countplot(data=data, x=feature, hue='Churn', palette="viridis")
    else:  # Si numérique
        sns.boxplot(data=data, x='Churn', y=feature, palette="viridis")

    plt.title(f"Distribution de {feature} par Churn")
    plt.ylabel("Count" if data[feature].dtype == 'object' or data[feature].nunique() < 20 else feature)
    plt.xlabel(feature)
    plt.legend(title='Churn', loc="upper right")
    plt.show()

"""LINEAR REGRESSION"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Exemple de données fictives
from sklearn.datasets import make_regression
X, y = make_regression(n_samples=100, n_features=1, noise=0.1, random_state=42)

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Créer et entraîner le modèle
model = LinearRegression()
model.fit(X_train, y_train)

# Prédiction et évaluation
y_pred = model.predict(X_test)
print("MSE:", mean_squared_error(y_test, y_pred))

import pandas as pd

# Supposons que features soit un tableau numpy ou une liste, vous pouvez le convertir en DataFrame
X_train = pd.DataFrame(features  )# Remplacez 'features_train' par vos données
X_test = pd.DataFrame(features_testing)    # Remplacez 'features_test' par vos données

# Vérifiez que X_train est bien un DataFrame
print(type(X_train))  # Cela doit maintenant afficher <class 'pandas.core.frame.DataFrame'>
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
# Appliquer le LabelEncoder à chaque colonne catégorielle dans X_train et X_test
for column in X_train.select_dtypes(include=['object']).columns:
    X_train[column] = label_encoder.fit_transform(X_train[column])
    X_test[column] = label_encoder.transform(X_test[column])

# Vérifiez les types de colonnes après transformation
print(X_train.dtypes)

print(data.head())  # Aperçu des premières lignes
print(data_testing.head())

"""TREE DECISION"""

common_rows = pd.merge(X_train, X_test, how='inner')
print(f"Nombre de lignes communes entre X_train et X_test : {len(common_rows)}")
common_rows.shape

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score, classification_report, mean_squared_error




X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

model = DecisionTreeRegressor(max_depth=5, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")

import numpy as np

# Vérifiez les classes dans y_train et y_test
print("Valeurs uniques dans y_train :", np.unique(y_train))
print("Valeurs uniques dans y_test :", np.unique(y_test))

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Initialiser le modèle de régression
model = DecisionTreeRegressor(random_state=42, max_depth=5)

# Entraîner le modèle
model.fit(X_train, y_train)

# Prédictions
y_pred = model.predict(X_test)

# Évaluation du modèle
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE) : {mse:.2f}")
print(f"R-squared (R²) : {r2:.2f}")

import pandas as pd

y_train_series = pd.Series(y_train)
print(y_train_series.head())  # Utiliser head() sur un pandas.Series

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Create and train the regressor
model = DecisionTreeRegressor(random_state=42, max_depth=5)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Calculate and print regression metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"R² Score: {r2:.2f}")

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report


X_train = data.iloc[:, :-1]
y_train = data.iloc[:, -1]

X_test = data_testing.iloc[:, :-1]
y_test = data_testing.iloc[:, -1]


model = DecisionTreeClassifier(random_state=42, max_depth=5)
model.fit(X_train, y_train)


y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred) * 100  # Accuracy en pourcentage
classification_rep = classification_report(y_test, y_pred, output_dict=True)
precision_macro = classification_rep["macro avg"]["precision"] * 100
f1_score_macro = classification_rep["macro avg"]["f1-score"] * 100
print(f"Accuracy: {accuracy:.2f}%")
print(f"Précision moyenne (macro): {precision_macro:.2f}%")
print(f"F1-score moyen (macro): {f1_score_macro:.2f}%\n")
print("Rapport de classification détaillé:")
print(classification_report(y_test, y_pred))

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10))
plot_tree(
    model,
    feature_names=X_train.columns,
    class_names=[str(cls) for cls in model.classes_],
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title("Arbre de décision ")
plt.show()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report

# Appliquer KNN
model_knn = KNeighborsClassifier(n_neighbors=5)
model_knn.fit(X_train, y_train)
y_pred_knn = model_knn.predict(X_test)

# Évaluer la précision et F1-score pour KNN
accuracy_knn = accuracy_score(y_test, y_pred_knn)
f1_knn = f1_score(y_test, y_pred_knn)

# Affichage des résultats pour KNN
print(f"KNN - Précision : {accuracy_knn * 100:.2f}%")
print(f"KNN - F1-score : {f1_knn:.2f}")
print("Rapport de classification - KNN :")
print(classification_report(y_test, y_pred_knn))

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, classification_report

# Appliquer SVM
model_svm = SVC(random_state=42)
model_svm.fit(X_train, y_train)
y_pred_svm = model_svm.predict(X_test)

# Évaluer la précision et F1-score pour SVM
accuracy_svm = accuracy_score(y_test, y_pred_svm)
f1_svm = f1_score(y_test, y_pred_svm)

# Affichage des résultats pour SVM
print(f"SVM - Précision : {accuracy_svm * 100:.2f}%")
print(f"SVM - F1-score : {f1_svm:.2f}")
print("Rapport de classification - SVM :")
print(classification_report(y_test, y_pred_svm))

"""RANDOM FOREST"""

from sklearn.ensemble import RandomForestClassifier

from sklearn.linear_model import LinearRegression

from sklearn.metrics import f1_score
model = LinearRegression()

# Entraînez le modèle
model.fit(X_train, y_train)

# Faites des prédictions
y_pred = model.predict(X_test)
model = RandomForestClassifier(random_state=42, max_depth=5)

# Entraîner le modèle sur les données d'entraînement
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Évaluer la précision du modèle
accuracy = accuracy_score(y_test, y_pred)*100

# Afficher la précision
print(f"Accuracy: {accuracy:.2f}%")
from sklearn.metrics import classification_report
# Rapport de classification détaillé
print(classification_report(y_test, y_pred))

"""ADABOOSTING"""

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import AdaBoostClassifier

# Créez un modèle
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score
model = LinearRegression()

base_model = DecisionTreeClassifier(max_depth=1)  # Un arbre de décision de faible profondeur
model = AdaBoostClassifier(base_model, n_estimators=100, random_state=42)  # n_estimators ajustable
model.fit(X_train, y_train)

# Faire des prédictions
y_pred = model.predict(X_test)

# Évaluer la précision du modèle
accuracy = accuracy_score(y_test, y_pred) * 100  # Convertir en pourcentage

# Afficher la précision
print(f"Accuracy: {accuracy:.2f}%")

# Rapport de classification détaillé
print("Rapport de classification détaillé:")
print(classification_report(y_test, y_pred))

"""LOGISTIC REGRSSION"""

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
# Créer et entraîner le modèle de régression logistique
model = LogisticRegression(max_iter=1000, random_state=42)  # max_iter peut être ajusté pour la convergence
model.fit(X_train, y_train)

# Faire des prédictions
y_pred = model.predict(X_test)

# Évaluer la précision du modèle
accuracy = accuracy_score(y_test, y_pred) * 100  # Convertir en pourcentage

# Afficher la précision
print(f"Accuracy: {accuracy:.2f}%")

# Rapport de classification détaillé
print("Rapport de classification détaillé:")
print(classification_report(y_test, y_pred))

# Gradient Boosting
from sklearn.ensemble import GradientBoostingClassifier

gbm_model = GradientBoostingClassifier(random_state=42)
gbm_model.fit(X_train, y_train)


y_pred = gbm_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}%")
print("Rapport de classification report:")
print( classification_rep)

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Créer la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Afficher la matrice de confusion sous forme graphique
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title("Matrice de confusion")
plt.show()

from sklearn.metrics import roc_auc_score, roc_curve, f1_score

# Calculer le F1-score
f1 = f1_score(y_test, y_pred, average="binary")  # Adapte "binary" ou "weighted" selon ton problème
print(f"F1-score: {f1:.2f}")

# Calculer le ROC-AUC (si applicable pour classification binaire)
if len(model.classes_) == 2:
    y_proba = model.predict_proba(X_test)[:, 1]  # Probabilités pour la classe positive
    auc_score = roc_auc_score(y_test, y_proba)
    print(f"ROC-AUC Score: {auc_score:.2f}")

    # Tracer la courbe ROC
    fpr, tpr, thresholds = roc_curve(y_test, y_proba)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {auc_score:.2f})")
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate (Recall)")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()
else:
    print("ROC-AUC et courbe ROC ne s'appliquent pas à la classification multi-classes.")

# Analyse des cas mal classifiés
print("\nCas mal classifiés :")
misclassified = pd.DataFrame({"y_test": y_test, "y_pred": y_pred})
misclassified = misclassified[misclassified["y_test"] != misclassified["y_pred"]]
print(misclassified.head())

import matplotlib.pyplot as plt

# Configuration de la figure
plt.figure(figsize=(10, 7))

# Visualisation avec des couleurs personnalisées et des bordures
misclassified["y_test"].value_counts().plot(
    kind='bar',
    color='skyblue',
    edgecolor='black',
    alpha=0.9
)

# Ajouter un titre et des labels
plt.title("Distribution des cas mal classifiés", fontsize=16, fontweight='bold')
plt.xlabel("Classe réelle", fontsize=10)
plt.ylabel("Nombre de cas", fontsize=10)

# Ajouter les valeurs au-dessus des barres
for i, v in enumerate(misclassified["y_test"].value_counts()):
    plt.text(i, v + 0.5, str(v), ha='center', fontsize=10)

# Amélioration du style des axes
plt.xticks(rotation=0, fontsize=8)
plt.yticks(fontsize=8)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Afficher le graphique
plt.tight_layout()
plt.show()

# Importance des caractéristiques
feature_importances = pd.Series(abs(model.coef_[0]), index=features.columns)
feature_importances = feature_importances.sort_values(ascending=False)

plt.figure(figsize=(10, 6))
feature_importances.plot(kind='bar', color='skyblue')
plt.title("Importance des caractéristiques (Coefficients absolus)")
plt.xlabel("Caractéristiques")
plt.ylabel("Importance")
plt.show()

from sklearn.model_selection import cross_val_score

# Validation croisée avec 5 plis
scores = cross_val_score(model, X_train, y_train, cv=5, scoring="accuracy")
print("Scores de validation croisée :", scores)
print("Score moyen :", scores.mean())

from sklearn.svm import SVC

# Essayer un SVM
svm_model = SVC(kernel='linear', probability=True)
svm_model.fit(X_train, y_train)
y_pred_svm = svm_model.predict(X_test)

print("Accuracy (SVM):", accuracy_score(y_test, y_pred_svm))
print("Classification Report (SVM):\n", classification_report(y_test, y_pred_svm))

from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

# Courbe Précision-Rappel (uniquement pour classification binaire)
if len(model.classes_) == 2:
    precision, recall, _ = precision_recall_curve(y_test, y_proba)  # y_proba : probabilités de prédiction
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, label="Courbe Précision-Rappel")
    plt.xlabel("Rappel")
    plt.ylabel("Précision")
    plt.title("Courbe Précision-Rappel")
    plt.legend(loc="best")
    plt.show()

from sklearn.metrics import average_precision_score

ap = average_precision_score(y_test, y_proba)
print(f"Précision Moyenne (AP): {ap:.2f}")

"""une précision moyenne (AP) de 0.86 est généralement considérée comme bonne. Cela indique que ton modèle a une capacité assez forte à distinguer les classes positives tout en maintenant un bon compromis entre précision et rappel.

"""

# prompt: i want to see the best model that have the best accuracy

import pandas as pd
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score
from sklearn.model_selection import cross_val_score

# Assuming you have already trained various models (DecisionTreeClassifier, KNN, SVM, RandomForestClassifier, etc.)
# and stored their predictions in y_pred_dt, y_pred_knn, y_pred_svm, y_pred_rf, etc.

# Create a dictionary to store model names and their corresponding accuracy scores
model_accuracies = {}

# Evaluate and store the accuracy of each model
model_accuracies['Decision Tree'] = accuracy_score(y_test, y_pred) * 100  # Assuming y_pred from Decision Tree
model_accuracies['KNN'] = accuracy_score(y_test, y_pred_knn) * 100
model_accuracies['SVM'] = accuracy_score(y_test, y_pred_svm) * 100
model_accuracies['Random Forest'] = accuracy_score(y_test, y_pred) * 100 # Assuming y_pred from RandomForest


# Find the best model
best_model = max(model_accuracies, key=model_accuracies.get)
best_accuracy = model_accuracies[best_model]

print(f"Best Model: {best_model}")
print(f"Best Accuracy: {best_accuracy:.2f}%")


# Display the classification report for the best model.  You will need to adapt based on which y_pred variable corresponds to the best model
if best_model == 'Decision Tree':
    print(classification_report(y_test, y_pred))
elif best_model == 'KNN':
    print(classification_report(y_test, y_pred_knn))
elif best_model == 'SVM':
    print(classification_report(y_test, y_pred_svm))
elif best_model == 'Random Forest':
    print(classification_report(y_test, y_pred))

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score, f1_score
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.datasets import make_regression
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
import numpy as np



# RANDOM FOREST (Corrected)
X_train = data.drop(columns=['Churn'])
y_train = data['Churn']
X_test = data_testing.drop(columns=['Churn'])
y_test = data_testing['Churn']
print(X_test)
print(y_test)

model_rf = RandomForestClassifier(random_state=42, max_depth=5)
model_rf.fit(X_train, y_train)
y_pred_rf = model_rf.predict(X_test)

accuracy_rf = accuracy_score(y_test, y_pred_rf) * 100
print(f"Random Forest - Accuracy: {accuracy_rf:.2f}%")
print(classification_report(y_test, y_pred_rf))


# ... (Rest of your existing code) ...


# Model Comparison (Corrected)

model_accuracies = {}
model_accuracies['Decision Tree'] = accuracy_score(y_test, y_pred) * 100
model_accuracies['KNN'] = accuracy_score(y_test, y_pred_knn) * 100
model_accuracies['SVM'] = accuracy_score(y_test, y_pred_svm) * 100
model_accuracies['Random Forest'] = accuracy_score(y_test, y_pred_rf) * 100  # Use y_pred_rf here

best_model = max(model_accuracies, key=model_accuracies.get)
best_accuracy = model_accuracies[best_model]

print(f"Best Model: {best_model}")
print(f"Best Accuracy: {best_accuracy:.2f}%")

# Display classification report for the best model (Corrected)

if best_model == 'Decision Tree':
    print(classification_report(y_test, y_pred))
elif best_model == 'KNN':
    print(classification_report(y_test, y_pred_knn))
elif best_model == 'SVM':
    print(classification_report(y_test, y_pred_svm))
elif best_model == 'Random Forest':
    print(classification_report(y_test, y_pred_rf)) # Use y_pred_rf here

# prompt: i want to save decision tree model

import joblib

# ... (Your existing code) ...

# Assuming 'model' is your trained DecisionTreeClassifier
# Save the model to a file
joblib.dump(model, 'decision_tree_model.joblib')