# -*- coding: utf-8 -*-
"""travail-final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zwkrQUQ8bmSCglLXgQ9yISJaMtsYzMZP
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats

df1 = pd.read_csv('/content/churn-bigml-80.csv')
df2 = pd.read_csv('/content/churn-bigml-20.csv')

def num_cols(df):
    return df.select_dtypes(include=['int64', 'float64']).columns
#
def bool_cols(df):
    return df.select_dtypes(include=['bool']).columns

#
def cat_cols(df):
    return df.select_dtypes(include=['object', 'category']).columns

# Summary print function
def print_feature_summary(df):
    num_features = num_cols(df)
    bool_features = bool_cols(df)
    cat_features = cat_cols(df)

    print("Numerical features:",len(num_features))
    if len(num_features) > 0:
        print("\n".join(num_features))
    else:
        print("None")
    print("*" * 35)

    print("Boolean features:",len(bool_features))
    if len(bool_features) > 0:
        print("\n".join(bool_features))
    else:
        print("None")
    print("*" * 35)

    print("Categorical features:",len(cat_features))
    if len(cat_features) > 0:
        print("\n".join(cat_features))
    else:
        print("None")
    print("*" * 35)

def is_continuous(df, feature, threshold=0.05):
    unique_count = df[feature].nunique()
    dataset_size = len(df)
    if pd.api.types.is_numeric_dtype(df[feature]) and unique_count > 10 and (unique_count / dataset_size) > threshold:
        return True
    return False


def continuous_discrete(df, save_path="feature_classification.png"):
    # Identify numerical columns
    numerical_features = num_cols(df)

    # Classify features as continuous or discrete
    continuous_features = []
    discrete_features = []

    for feature in numerical_features:
        if is_continuous(df, feature):
            continuous_features.append(feature)
        else:
            discrete_features.append(feature)
    # Save the lists
    with open("continuous_features.txt", "w") as f:
        f.write("Continuous Features:\n")
        for feature in continuous_features:
            f.write(f"- {feature}\n")

    with open("discrete_features.txt", "w") as f:
        f.write("Discrete Features:\n")
        for feature in discrete_features:
            f.write(f"- {feature}\n")

    # Return the precise lists for further use
    return continuous_features, discrete_features

def check_normality(df, continuous_features):
    for feature in continuous_features:
        # Perform the Shapiro-Wilk test for normality
        stat, p_value = stats.shapiro(df[feature])

        # If p-value is greater than 0.05, assume the feature follows a normal distribution
        is_normal = p_value > 0.05
        normal_status = "Normal" if is_normal else "Not-Normal"

        # Print the result for each feature
        print(f"{feature}: {normal_status}")
def detect_outliers_by_zscore(df, columns, threshold=3):
    outliers = {}

    for col in columns:
        # Calculate Z-scores
        z_scores = (df[col] - df[col].mean()) / df[col].std()

        # Detect outliers (Z-score > threshold or < -threshold)
        outliers[col] = df.index[np.abs(z_scores) > threshold].tolist()

    return outliers

def check_total_intl_charge_distribution(df):
    # Filter the dataframe where 'International plan' is True
    df_filtered = df[df['International plan'] == 'Yes']

    # Check if the filtered dataframe is not empty
    if not df_filtered.empty:
        # Perform the Shapiro-Wilk test for normality on 'Total intl charge'
        stat, p_value = stats.shapiro(df_filtered['Total intl charge'])

        # If p-value is greater than 0.05, assume the feature follows a normal distribution
        is_normal = p_value > 0.05
        normal_status = "Normal" if is_normal else "Not-Normal"

        # Print the result
        print(f"Total intl charge distribution (when 'International plan' is True): {normal_status}")
    else:
        print("No rows where 'International plan' is True")

def replace_outliers_with_mean(df, columns):
    result = {}

    for col in columns:
        # Calculate Z-score for the column
        z_scores = (df[col] - df[col].mean()) / df[col].std()

        # Identify outliers (Z-score > 3 or < -3)
        outliers = np.abs(z_scores) > 3

        # Replace outliers with the mean value of the column
        df[col] = df[col].where(~outliers, df[col].mean())

        # Store the results in the dictionary
        for idx, value in df[col].iteritems():
            result[idx] = result.get(idx, []) + [[col, value]]

    return result

def replace_outliers_with_mean_intl(df, columns, plan_column='International plan', plan_value=True):
    result = {}

    # Filter the DataFrame to include only rows where the plan_column is True
    filtered_df = df[df[plan_column] == plan_value]

    for col in columns:
        # Calculate Z-scores for the column in the filtered DataFrame
        z_scores = (filtered_df[col] - filtered_df[col].mean()) / filtered_df[col].std()

        # Identify outliers (Z-score > 3 or < -3)
        outliers = np.abs(z_scores) > 3

        # Replace outliers with the mean value of the column only for the filtered rows
        df.loc[filtered_df.index, col] = df.loc[filtered_df.index, col].where(~outliers, df[col].mean())

        # Store the results in the dictionary
        for idx in filtered_df.index:  # Only iterate over the filtered rows
            value = df.at[idx, col]  # Access the value using .at for specific row/column
            result[idx] = result.get(idx, []) + [[col, value]]

    return result


def detect_outliers_iqr(df, column):
    # Calculate Q1 (25th percentile) and Q3 (75th percentile)
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)

    # Calculate IQR
    IQR = Q3 - Q1

    # Calculate the lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Identify outliers and their indices
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]

    # Return outlier indices and values as a dictionary
    outlier_info = outliers[column].to_dict()

    return outlier_info


def detect_outliers_iqr(df, column):
    # Calculate Q1 (25th percentile) and Q3 (75th percentile)
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)

    # Calculate IQR
    IQR = Q3 - Q1

    # Calculate the lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Identify outliers and their indices
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]

    # Return outlier indices and values as a dictionary
    outlier_info = outliers[column].to_dict()

    return outlier_info


def replace_outliers_iqr(df, columns):
    for column in columns:
        # Calculate Q1 (25th percentile) and Q3 (75th percentile)
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)

        # Calculate the Interquartile Range (IQR)
        IQR = Q3 - Q1

        # Define the outlier threshold (1.5 * IQR)
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Identify outliers
        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]

        # Get the median of the column
        median_value = df[column].median()

        # Replace outliers with the median value
        df[column] = df[column].apply(lambda x: median_value if x in outliers[column].values else x)

    return df

def replace_outliers_with_mean(df, columns):
    """
    Replace outliers in specified columns using the z-score method
    Args:
        df: DataFrame
        columns: List of column names to process
    Returns:
        Dictionary containing the replacement results
    """
    result = {}

    for col in columns:
        # Calculate Z-score for the column
        z_scores = (df[col] - df[col].mean()) / df[col].std()

        # Identify outliers (Z-score > 3 or < -3)
        outliers = np.abs(z_scores) > 3

        # Replace outliers with the mean value of the column
        df[col] = df[col].where(~outliers, df[col].mean())

        # Store the results in the dictionary using items() instead of iteritems()
        for idx, value in df[col].items():
            result[idx] = result.get(idx, []) + [[col, value]]

    return result

# Also fix the international plan function
def replace_outliers_with_mean_intl(df, columns, plan_column='International plan', plan_value='Yes'):
    """
    Replace outliers for customers with international plan
    Args:
        df: DataFrame
        columns: List of column names to process
        plan_column: Column name for plan type
        plan_value: Value indicating international plan
    Returns:
        Dictionary containing the replacement results
    """
    result = {}

    # Filter the DataFrame
    filtered_df = df[df[plan_column] == plan_value]

    for col in columns:
        # Calculate Z-scores for the filtered data
        z_scores = (filtered_df[col] - filtered_df[col].mean()) / filtered_df[col].std()

        # Identify outliers
        outliers = np.abs(z_scores) > 3

        # Replace outliers only for filtered rows
        df.loc[filtered_df.index, col] = df.loc[filtered_df.index, col].where(~outliers, filtered_df[col].mean())

        # Store results
        for idx in filtered_df.index:
            value = df.at[idx, col]
            result[idx] = result.get(idx, []) + [[col, value]]

    return result

# Now you can use the functions
normal_features = [
    'Total day minutes',
    'Total eve minutes',
    'Total night minutes'
]

# Apply the functions
replace_outliers_with_mean(df1, normal_features)
replace_outliers_with_mean_intl(df1, ['Total intl minutes'], plan_column='International plan', plan_value='Yes')

"""### imputation(non_normal)"""

def replace_outliers_with_median(df, column):
    """
    Replace outliers in a column with the median value using IQR method
    Args:
        df: DataFrame
        column: Column name to process
    Returns:
        DataFrame with outliers replaced
    """
    # Calculate Q1 (25th percentile) and Q3 (75th percentile)
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)

    # Calculate IQR
    IQR = Q3 - Q1

    # Calculate the lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Create a copy of the DataFrame
    df_copy = df.copy()

    # Identify outliers
    outliers = (df_copy[column] < lower_bound) | (df_copy[column] > upper_bound)

    # Replace outliers with median
    median_value = df_copy[column].median()
    df_copy.loc[outliers, column] = median_value

    return df_copy

# Now you can use the function
df1 = replace_outliers_with_median(df1, 'Account length')

# Verify the changes
print("\nStats for Account length after outlier treatment:")
print(df1['Account length'].describe())

df1 = replace_outliers_with_median(df1, 'Account length')

"""### imputate with iqr for discrete"""

###

discrete = ['Total day calls', 'Total eve calls', 'Total night calls']
df1 = replace_outliers_iqr(df1, discrete)

def replace_outliers_iqr_intl(df, column, plan_column='International plan', plan_value='Yes'):
    """
    Replace outliers using IQR method for customers with international plan
    Args:
        df: DataFrame
        column: Column name to process
        plan_column: Column name for plan type
        plan_value: Value indicating international plan
    Returns:
        DataFrame with outliers replaced
    """
    # Create a copy of the DataFrame
    df_copy = df.copy()

    # Filter for international plan customers
    filtered_df = df_copy[df_copy[plan_column] == plan_value]

    if not filtered_df.empty:
        # Calculate Q1 (25th percentile) and Q3 (75th percentile)
        Q1 = filtered_df[column].quantile(0.25)
        Q3 = filtered_df[column].quantile(0.75)

        # Calculate IQR
        IQR = Q3 - Q1

        # Calculate the lower and upper bounds
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Identify outliers only for international plan customers
        outliers = (filtered_df[column] < lower_bound) | (filtered_df[column] > upper_bound)

        # Get median value for replacement
        median_value = filtered_df[column].median()

        # Replace outliers only for international plan customers
        df_copy.loc[filtered_df[outliers].index, column] = median_value

    return df_copy

# Now you can use the function
df1 = replace_outliers_iqr_intl(df1, 'Total intl calls', plan_column='International plan', plan_value='Yes')

# Verify the changes
print("\nStats for Total intl calls (International plan customers) after outlier treatment:")
print(df1[df1['International plan'] == 'Yes']['Total intl calls'].describe())

# You can also compare before and after statistics
print("\nBefore and after comparison for international plan customers:")
filtered_before = df1[df1['International plan'] == 'Yes']['Total intl calls']
filtered_after = df1[df1['International plan'] == 'Yes']['Total intl calls']

print("\nBefore:")
print(filtered_before.describe())
print("\nAfter:")
print(filtered_after.describe())

df1 = replace_outliers_iqr_intl(df1, 'Total intl calls', plan_column='International plan', plan_value='Yes')

"""### Apply binning of customer service calls and nbre voice mail messages"""

df1.info()

df1['Customer service calls'].nunique()



df1.info()







from sklearn.preprocessing import LabelEncoder



# 1. Label Encoding for the 'Customer service calls' column
# Initialize the label encoder
label_encoder = LabelEncoder()

# Apply label encoding on the 'Customer service calls' column
df1['Customer_service_calls_encoded'] = label_encoder.fit_transform(df1['Customer service calls'])


# 2. Binning the 'Customer_service_calls_encoded' column
# Define custom bins and labels for the encoded column
bins = [-1, 0, 2, 4, 6, 9]  # Adjust bin edges as needed
labels = ['0', '1-2', '3-4', '5-6', '7-9']  # Custom labels for bins

# Apply binning to the encoded column
df1['Customer_service_calls_binned'] = pd.cut(
    df1['Customer_service_calls_encoded'],
    bins=bins,
    labels=labels,
    right=True
)


# 3. Label Encoding the 'Customer_service_calls_binned' column
# Initialize a new LabelEncoder for the binned column
label_encoder_binned = LabelEncoder()

# Apply label encoding to the binned column
df1['Customer_service_calls_binned_encoded'] = label_encoder_binned.fit_transform(df1['Customer_service_calls_binned'])

df1.info()

L=['Customer_service_calls_encoded','Customer_service_calls_binned','Customer service calls']
df1=df1.drop(columns=L)

"""### Prepare dataset for training"""

L1=['State', 'Area code']
df_train=df1.drop(columns=L1)

df_train.info()

# Convert 'Voice mail plan' and 'International plan' to integer types
df_train['Voice mail plan'] = df_train['Voice mail plan'].map({'Yes': 1, 'No': 0})
df_train['International plan'] = df_train['International plan'].map({'Yes': 1, 'No': 0})

# Check the new DataFrame info
print(df_train.info())



#df1.to_csv('/kaggle/working/df_train', index=False)

"""### Prepare test dataset"""

df2['International plan'] = df2['International plan'].map({'Yes': 1, 'No': 0})
df2['Voice mail plan'] = df2['Voice mail plan'].map({'Yes': 1, 'No': 0})

def delete(df,L):
    return df.drop(columns=L)

# Step 2: Apply Label Encoding to 'Customer service calls'
label_encoder = LabelEncoder()
df2['Customer_service_calls_encoded'] = label_encoder.fit_transform(df2['Customer service calls'])

# Step 3: Apply Binning to 'Customer_service_calls_encoded'
bins = [-1, 0, 2, 4, 6, 9]  # Adjust bin edges as needed
labels = ['0', '1-2', '3-4', '5-6', '7-9']  # Custom labels for bins

df2['Customer_service_calls_binned'] = pd.cut(df2['Customer_service_calls_encoded'],
                                               bins=bins,
                                               labels=labels,
                                               right=True)

# Step 4: Encode the binned values
df2['Customer_service_calls_binned_encoded'] = label_encoder.fit_transform(df2['Customer_service_calls_binned'])

# Step 5: Drop unnecessary columns (State, Area code)
df2 = df2.drop(columns=['State', 'Area code'])

df2.info()

df_Test = df2.drop(['Customer_service_calls_encoded', 'Customer_service_calls_binned', 'Customer service calls'], axis=1)

df_Test.info()

L1=['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

df_train=delete(df_train,L1)
df_Test=delete(df2,L1)

df_Test = df_Test.drop(columns=['Customer_service_calls_encoded','Customer service calls','Customer_service_calls_binned'])

df_train.info()

# First, ensure we have df_Test
df_Test = df2.drop(columns=['Customer_service_calls_encoded', 'Customer service calls', 'Customer_service_calls_binned'])

# Then assign it to df_test (note the capitalization)
df_test = df_Test

# Now add the Churn column from df2
df_test['Churn'] = df2['Churn']

# Now you can check the info
df_test.info()

df_test= df_Test

df_test['Churn']=df2['Churn']

df_train.info()

# Step 1: Import necessary libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split

# Step 2: First, let's make sure both datasets have the same columns
# List of charge columns to remove from test set
charge_columns = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

# Remove charge columns from test set
X_test = df_test.drop(columns=['Churn'] + charge_columns)
y_test = df_test['Churn']

# Step 3: Prepare training data
X = df_train.drop(columns=['Churn'])  # Features
y = df_train['Churn']    # Target

# Verify columns match
print("Training columns:", X.columns.tolist())
print("Test columns:", X_test.columns.tolist())

# Step 4: Split training data into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Train the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Step 6: Evaluate on validation set
y_val_pred = rf_model.predict(X_val)

# Calculate validation metrics
accuracy = accuracy_score(y_val, y_val_pred)
print(f"\nValidation Accuracy: {accuracy * 100:.2f}%")
print("\nValidation Classification Report:")
print(classification_report(y_val, y_val_pred))
print("\nValidation Confusion Matrix:")
print(confusion_matrix(y_val, y_val_pred))

# Step 7: Evaluate on test set
y_test_pred = rf_model.predict(X_test)

# Print test set results
print("\nTest Set Results:")
print(f"Test Accuracy: {accuracy_score(y_test, y_test_pred) * 100:.2f}%")
print("\nTest Classification Report:")
print(classification_report(y_test, y_test_pred))
print("\nTest Confusion Matrix:")
print(confusion_matrix(y_test, y_test_pred))

# Step 8: Print feature importance
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': rf_model.feature_importances_
})
print("\nFeature Importance:")
print(feature_importance.sort_values('importance', ascending=False))

# Import necessary libraries
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Load your training dataset
# Assuming df_train is already loaded as per your earlier description
# df_train = pd.read_csv('your_train_data.csv')

# Preprocessing
# Encode target variable 'Churn' if it's in boolean form (True/False)
df_train['Churn'] = df_train['Churn'].astype(int)

# Select features (X) and target variable (y)
X_train = df_train.drop('Churn', axis=1)
y_train = df_train['Churn']

# Normalize the numerical features
scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_train_scaled[['Total day minutes', 'Total eve minutes', 'Total night minutes', 'Total intl minutes']] = \
    scaler.fit_transform(X_train[['Total day minutes', 'Total eve minutes', 'Total night minutes', 'Total intl minutes']])

# Use StratifiedKFold for cross-validation to ensure balanced class distribution
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Initialize RandomForestClassifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Perform cross-validation and get the mean accuracy
cv_scores = cross_val_score(rf, X_train_scaled, y_train, cv=cv, scoring='accuracy')

# Print the cross-validation results
print(f'Cross-validation accuracy scores: {cv_scores}')
print(f'Mean cross-validation accuracy: {cv_scores.mean()}')

# Optionally: Fit on the entire training set and evaluate on test set later
rf.fit(X_train_scaled, y_train)

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Set up a parameter grid
param_grid = {
    'n_estimators': [50, 100, 150, 200],  # Number of trees in the forest
    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree
    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node
    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node
    'max_features': ['sqrt', 'log2'],  # Number of features to consider when looking for the best split
    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees
}

# Initialize the RandomForestClassifier
rf = RandomForestClassifier(random_state=42)

# Set up GridSearchCV
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,
                           cv=5, scoring='accuracy', n_jobs=-1, verbose=2)

# Fit GridSearchCV to the training data
grid_search.fit(X_train_scaled, y_train)

# Retrieve the best parameters
best_params = grid_search.best_params_

# Print the best hyperparameters
print("Best hyperparameters found:", best_params)

# Optionally, you can check the best score (mean accuracy)
print(f"Best cross-validation accuracy: {grid_search.best_score_}")

# Import necessary libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# First, make sure both datasets have the same columns by removing charge columns
charge_columns = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

# Step 1: Prepare training data
X_train = df_train.drop('Churn', axis=1)  # Features
y_train = df_train['Churn']  # Target

# Step 2: Prepare test data by removing charge columns
X_test = df_test.drop(['Churn'] + charge_columns, axis=1)  # Features and charge columns
y_test = df_test['Churn']  # Target

# Verify columns match
print("Training columns:", X_train.columns.tolist())
print("Test columns:", X_test.columns.tolist())

# Step 3: Define the Random Forest model with the best hyperparameters
rf_model = RandomForestClassifier(
    bootstrap=False,
    max_depth=None,
    max_features='sqrt',
    min_samples_leaf=1,
    min_samples_split=5,
    class_weight='balanced',
    n_estimators=150,
    random_state=42
)

# Step 4: Train the model
rf_model.fit(X_train, y_train)

# Step 5: Predict on the test data
y_pred = rf_model.predict(X_test)

# Step 6: Evaluate the model
# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'\nAccuracy: {accuracy:.2f}')

# Classification report
print('\nClassification Report:')
print(classification_report(y_test, y_pred))

# Confusion matrix
print('\nConfusion Matrix:')
print(confusion_matrix(y_test, y_pred))

# Optional: Print feature importance
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': rf_model.feature_importances_
})
print("\nFeature Importance:")
print(feature_importance.sort_values('importance', ascending=False))

import xgboost as xgb
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    f1_score,
    precision_score,
    recall_score
)
from sklearn.model_selection import train_test_split

# Remove charge columns from test data
charge_columns = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

X_train = df_train.drop(columns=['Churn'])  # Drop the target column
y_train = df_train['Churn']  # Target column for training

X_test = df_test.drop(columns=['Churn'] + charge_columns)  # Drop target and charge columns
y_test = df_test['Churn']  # Target column for testing

# Verify columns match
print("Training columns:", X_train.columns.tolist())
print("Test columns:", X_test.columns.tolist())

# Initialize XGBoost model with best parameters
model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    n_estimators=150,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=3,
    random_state=42
)

# Fit the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy: {accuracy:.2f}")

# Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Calculate additional metrics
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print(f"\nAdditional Metrics:")
print(f"F1-Score: {f1:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")

# Plot feature importance
xgb.plot_importance(model, importance_type='weight', max_num_features=10)
plt.show()

import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score

# Remove charge columns from test data
charge_columns = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

# Prepare training data
X_train = df_train.drop(columns=['Churn'])
y_train = df_train['Churn']

# Prepare test data
X_test = df_test.drop(columns=['Churn'] + charge_columns)
y_test = df_test['Churn']

# Initialize XGBoost model with the best parameters found
model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    n_estimators=100,  # Number of trees
    max_depth=10,  # Maximum depth of the trees
    learning_rate=0.05,  # Step size
    subsample=0.8,  # Subsampling ratio
    colsample_bytree=0.8,  # Subsample ratio for columns
    scale_pos_weight=3,  # Handling class imbalance, you can tune this value
    random_state=42
)
print("Training columns:", X_train.columns.tolist())
print("Test columns:", X_test.columns.tolist())

# Fit the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel Performance Metrics:")
print(f"Accuracy: {accuracy:.2f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("\nAdditional Performance Metrics:")
print(f"F1-Score: {f1:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")

# Plot feature importance
xgb.plot_importance(model, importance_type='weight', max_num_features=10)
plt.show()

import xgboost as xgb
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Define the parameter grid for RandomizedSearchCV
param_dist = {
    'n_estimators': [100, 150],  # Reduced number of trees
    'max_depth': [5, 10, 15],  # Reduced maximum depth of trees
    'learning_rate': [0.05, 0.1],  # Reduced learning rate options
    'subsample': [0.7, 0.8],  # Reduced subsample ratio
    'colsample_bytree': [0.8],  # Fixed subsample ratio for columns
    'scale_pos_weight': [3],  # Fixed value for handling class imbalance
}

# XGBoost classifier with default parameters
model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    random_state=42
)

# Perform RandomizedSearchCV for hyperparameter tuning
random_search = RandomizedSearchCV(
    model,
    param_distributions=param_dist,
    n_iter=10,  # Reduced iterations to 10 for faster tuning
    cv=3,  # Reduced folds to 3
    verbose=1,
    random_state=42,
    n_jobs=-1  # Use all available CPU cores for parallelism
)

# Fit the model to the training data
random_search.fit(X_train, y_train)

# Print the best parameters from RandomizedSearchCV
print(f"Best parameters: {random_search.best_params_}")

# Get the best model from the search
best_model = random_search.best_estimator_

# Evaluate the best model on the test data
y_pred = best_model.predict(X_test)

# Calculate the accuracy
accuracy = np.mean(y_pred == y_test)
print(f"Accuracy: {accuracy:.2f}")

# Print the classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Print the confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Optional: Use early stopping during model fitting for further optimization
# If needed, you can add early stopping as follows (not necessary for RandomizedSearchCV):
# best_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=True)

import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Assuming df_train and df_test are your DataFrames
# Let's separate features and target variable for both training and testing sets

X_train = df_train.drop(columns=['Churn'])  # Drop the target column
y_train = df_train['Churn']  # Target column for training

X_test = df_test.drop(columns=['Churn'])  # Drop the target column
y_test = df_test['Churn']  # Target column for testing
X_test = df_test.drop(columns=['Churn'] + charge_columns, axis=1)
# Initialize XGBoost model with the tuned hyperparameters
model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    n_estimators=100,  # Number of trees
    max_depth=10,  # Maximum depth of the trees
    learning_rate=0.05,  # Step size
    subsample=0.8,  # Subsampling ratio
    colsample_bytree=0.8,  # Subsample ratio for columns
    scale_pos_weight=3,  # Handling class imbalance, you can tune this value
    random_state=42
)

# Fit the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Optionally, you can also calculate the F1-Score, Precision, Recall directly
from sklearn.metrics import f1_score, precision_score, recall_score

f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print(f"F1-Score: {f1:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")





"""# DONT TOUCH, JUST ADD"""

def replace_outliers_with_mean(df, columns):
    result = {}

    for col in columns:
        # Calculate Z-score for the column
        z_scores = (df[col] - df[col].mean()) / df[col].std()

        # Identify outliers (Z-score > 3 or < -3)
        outliers = np.abs(z_scores) > 3

        # Replace outliers with the mean value of the column
        df[col] = df[col].where(~outliers, df[col].mean())

        # Store the results in the dictionary
        for idx, value in df[col].items():  # Use items() instead of iteritems()
            result[idx] = result.get(idx, []) + [[col, value]]

    return result

def replace_outliers_with_median(df, column):
    # Calculate Q1 (25th percentile) and Q3 (75th percentile)
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)

    # Calculate IQR
    IQR = Q3 - Q1

    # Calculate the lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Identify outliers
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]

    # Get the median of the column
    median_value = df[column].median()

    # Replace outliers with the median value
    df[column] = df[column].where(~df.index.isin(outliers.index), median_value)

    return df

def replace_outliers_iqr_intl(df, column, plan_column='International plan', plan_value='Yes'):
    # Filter the DataFrame to include only rows where the plan_column is set to plan_value
    filtered_df = df[df[plan_column] == plan_value]

    # Calculate Q1 (25th percentile) and Q3 (75th percentile) for the filtered data
    Q1 = filtered_df[column].quantile(0.25)
    Q3 = filtered_df[column].quantile(0.75)

    # Calculate IQR
    IQR = Q3 - Q1

    # Calculate the lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Identify outliers in the filtered data
    outliers = filtered_df[(filtered_df[column] < lower_bound) | (filtered_df[column] > upper_bound)]

    # Get the median of the column
    median_value = df[column].median()

    # Replace outliers in the original DataFrame with the median value
    df[column] = df[column].apply(lambda x: median_value if x in outliers[column].values else x)

    return df

def replace_outliers_with_mean_intl(df, columns, plan_column='International plan', plan_value=True):
    result = {}

    # Filter the DataFrame to include only rows where the plan_column is True
    filtered_df = df[df[plan_column] == plan_value]

    for col in columns:
        # Calculate Z-scores for the column in the filtered DataFrame
        z_scores = (filtered_df[col] - filtered_df[col].mean()) / filtered_df[col].std()

        # Identify outliers (Z-score > 3 or < -3)
        outliers = np.abs(z_scores) > 3

        # Replace outliers with the mean value of the column only for the filtered rows
        df.loc[filtered_df.index, col] = df.loc[filtered_df.index, col].where(~outliers, df[col].mean())

        # Store the results in the dictionary
        for idx in filtered_df.index:  # Only iterate over the filtered rows
            value = df.at[idx, col]  # Access the value using .at for specific row/column
            result[idx] = result.get(idx, []) + [[col, value]]

    return result

df_train.info()
df_test.info()

import matplotlib.pyplot as plt
xgb.plot_importance(model, importance_type='weight', max_num_features=10)
plt.show()

# Assuming X_train and y_train are already defined
# Train the RandomForest model (if not already trained)
rf_model = RandomForestClassifier(
    bootstrap=False,
    max_depth=None,
    max_features='sqrt',
    min_samples_leaf=1,
    min_samples_split=5,
    class_weight='balanced',
    n_estimators=150,
    random_state=42
)

# Fit the model on the training data
rf_model.fit(X_train, y_train)

# Get feature importances from the trained model
feature_importances = rf_model.feature_importances_

# Get feature names (assuming the DataFrame is called X_train)
feature_names = X_train.columns

# Sort the feature importances in descending order
sorted_idx = np.argsort(feature_importances)[::-1]

# Select the top 10 features
top_n = 10
top_idx = sorted_idx[:top_n]
top_feature_importances = feature_importances[top_idx]
top_feature_names = feature_names[top_idx]

# Plot the top 10 features
plt.figure(figsize=(10, 6))
plt.barh(top_feature_names, top_feature_importances, align='center')
plt.xlabel('Feature Importance')
plt.title('Top 10 Random Forest Feature Importances')
plt.gca().invert_yaxis()  # Invert the y-axis to display the most important features at the top
plt.show()

## best parameters for rf_model
rf_model = RandomForestClassifier(
    bootstrap=False,
    max_depth=None,
    max_features='sqrt',
    min_samples_leaf=1,
    min_samples_split=5,
    n_estimators=150,
    random_state=42
)
##best parameters for XGboost
model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    n_estimators=100,  # Number of trees
    max_depth=10,  # Maximum depth of the trees
    learning_rate=0.05,  # Step size
    subsample=0.8,  # Subsampling ratio
    colsample_bytree=0.8,  # Subsample ratio for columns
    scale_pos_weight=3,  # Handling class imbalance, you can tune this value
    random_state=42
)



import joblib
import xgboost as xgb
from sklearn.ensemble import RandomForestClassifier

# Save the RandomForest model
joblib.dump(rf_model, 'random_forest_model.pkl')

import xgboost as xgb
from sklearn.model_selection import train_test_split

# Assume X_train and y_train are your training features and labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define and fit the XGBoost model
model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    n_estimators=100,
    max_depth=10,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=3,
    random_state=42
)

# Fit the model to your training data
model.fit(X_train, y_train)

# Now save the model
model.save_model('xgboost_model.json')

# Load the saved XGBoost model
model_loaded = xgb.XGBClassifier()
model_loaded.load_model('xgboost_model.json')

joblib.dump(rf_model, '/kaggle/working/random_forest_model.pkl')

"""### LogisticRegression"""

# Step 1: Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib

# Step 2: Remove charge columns from test data
charge_columns = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

# Prepare training data
X_train = df_train.drop('Churn', axis=1)  # Features for training
y_train = df_train['Churn']  # Target for training

# Prepare test data by removing charge columns
X_test = df_test.drop(['Churn'] + charge_columns, axis=1)  # Features for testing
y_test = df_test['Churn']  # Target for testing

# Verify columns match
print("Training columns:", X_train.columns.tolist())
print("Test columns:", X_test.columns.tolist())

# Step 3: Scale the features using StandardScaler
scaler = StandardScaler()

# Fit the scaler on the training data and transform both training and test data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 4: Define and train the Logistic Regression model
log_reg_model = LogisticRegression(
    max_iter=200,
    solver='saga',
    random_state=42,
    class_weight='balanced'  # Added to handle class imbalance
)

# Train the model
log_reg_model.fit(X_train_scaled, y_train)

# Step 5: Make predictions on the test data
y_pred = log_reg_model.predict(X_test_scaled)

# Step 6: Evaluate the model
# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'\nModel Performance Metrics:')
print(f'Accuracy: {accuracy:.2f}')

# Classification report
print('\nClassification Report:')
print(classification_report(y_test, y_pred))

# Confusion matrix
print('\nConfusion Matrix:')
print(confusion_matrix(y_test, y_pred))

# Additional metrics
from sklearn.metrics import f1_score, precision_score, recall_score
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print('\nAdditional Performance Metrics:')
print(f'F1-Score: {f1:.2f}')
print(f'Precision: {precision:.2f}')
print(f'Recall: {recall:.2f}')

# Step 7: Feature Importance
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'coefficient': abs(log_reg_model.coef_[0])
})
print('\nFeature Importance:')
print(feature_importance.sort_values('coefficient', ascending=False))

# Step 8: Save the trained model and scaler for deployment
joblib.dump(log_reg_model, 'logistic_regression_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
print('\nModel and scaler saved successfully.')

# Example of how to load and use the saved model
def predict_churn(new_data):
    """
    Make churn predictions on new data
    Args:
        new_data: DataFrame with same features as training data
    Returns:
        Predictions (0 for no churn, 1 for churn)
    """
    # Load the saved model and scaler
    loaded_model = joblib.load('logistic_regression_model.pkl')
    loaded_scaler = joblib.load('scaler.pkl')

    # Scale the new data
    scaled_data = loaded_scaler.transform(new_data)

    # Make predictions
    predictions = loaded_model.predict(scaled_data)
    return predictions

# Import necessary libraries
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
import pandas as pd

# Remove charge columns from test data
charge_columns = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

# Step 1: Prepare the data
X_train = df_train.drop('Churn', axis=1)  # Features
y_train = df_train['Churn']  # Target

X_test = df_test.drop(['Churn'] + charge_columns, axis=1)  # Features
y_test = df_test['Churn']  # Target

# Verify columns match
print("Training columns:", X_train.columns.tolist())
print("Test columns:", X_test.columns.tolist())

# Step 2: Train the Gradient Boosting model with best parameters
gb_model = GradientBoostingClassifier(
    learning_rate=0.1,
    max_depth=3,
    min_samples_split=3,
    n_estimators=150,
    subsample=0.9,
    random_state=42
)

# Train the model
gb_model.fit(X_train, y_train)

# Step 3: Predict on the test data
y_pred = gb_model.predict(X_test)

# Step 4: Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'\nModel Performance Metrics:')
print(f'Accuracy: {accuracy:.2f}')

# Classification report
print('\nClassification Report:')
print(classification_report(y_test, y_pred))

# Confusion matrix
print('\nConfusion Matrix:')
print(confusion_matrix(y_test, y_pred))

# Additional metrics
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print('\nAdditional Performance Metrics:')
print(f'F1-Score: {f1:.2f}')
print(f'Precision: {precision:.2f}')
print(f'Recall: {recall:.2f}')

# Feature importance
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': gb_model.feature_importances_
}).sort_values('importance', ascending=False)

print('\nTop 10 Most Important Features:')
print(feature_importance.head(10))

# Save the model
import joblib
joblib.dump(gb_model, 'gradient_boosting_model.pkl')
print('\nModel saved as gradient_boosting_model.pkl')

# Example prediction function
def predict_churn(new_data):
    """
    Make churn predictions on new data
    Args:
        new_data: DataFrame with same features as training data
    Returns:
        Predictions (0 for no churn, 1 for churn)
    """
    # Load the saved model
    loaded_model = joblib.load('gradient_boosting_model.pkl')

    # Make predictions
    predictions = loaded_model.predict(new_data)
    return predictions

# Import necessary libraries
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score
import pandas as pd

# Remove charge columns from test data
charge_columns = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

# Prepare data
X_train = df_train.drop('Churn', axis=1)  # Features
y_train = df_train['Churn']  # Target

X_test = df_test.drop(['Churn'] + charge_columns, axis=1)  # Features
y_test = df_test['Churn']  # Target

# Verify columns match
print("Training columns:", X_train.columns.tolist())
print("Test columns:", X_test.columns.tolist())

# Define parameter grid
param_grid_gb = {
    'n_estimators': [100, 150],      # Number of trees
    'learning_rate': [0.01, 0.05, 0.1],  # Learning rate values
    'max_depth': [3, 5],             # Tree depth options
    'subsample': [0.8, 0.9],         # Sample fraction
    'min_samples_split': [2, 3]      # Min samples for split
}

# Initialize Gradient Boosting Classifier
gb = GradientBoostingClassifier(random_state=42)

# Set up GridSearchCV
print("\nStarting Grid Search...")
grid_search = GridSearchCV(
    estimator=gb,
    param_grid=param_grid_gb,
    cv=5,                # 5-fold cross-validation
    n_jobs=-1,          # Use all available cores
    verbose=1,
    scoring='accuracy'
)

# Fit the model
grid_search.fit(X_train, y_train)

# Print best parameters and score
print("\nGrid Search Results:")
print("Best Parameters:", grid_search.best_params_)
print("Best Cross-validation Score:", grid_search.best_score_)

# Get best model
best_gb_model = grid_search.best_estimator_

# Make predictions
y_pred = best_gb_model.predict(X_test)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

# Print results
print("\nModel Performance Metrics:")
print(f"Accuracy: {accuracy:.2f}")
print(f"F1-Score: {f1:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Feature importance analysis
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': best_gb_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 10 Most Important Features:")
print(feature_importance.head(10))

# Save the best model
import joblib
joblib.dump(best_gb_model, 'gradient_boosting_best_model.pkl')
print("\nBest model saved as gradient_boosting_best_model.pkl")

# Example prediction function
def predict_churn(new_data):
    """
    Make churn predictions on new data using the best model
    Args:
        new_data: DataFrame with same features as training data
    Returns:
        Predictions (0 for no churn, 1 for churn)
    """
    # Load the saved model
    loaded_model = joblib.load('gradient_boosting_best_model.pkl')

    # Make predictions
    predictions = loaded_model.predict(new_data)
    return predictions

# Print CV results for all parameter combinations
cv_results = pd.DataFrame(grid_search.cv_results_)
print("\nAll Parameter Combinations Results:")
print(cv_results[['mean_test_score', 'std_test_score', 'params']]
      .sort_values('mean_test_score', ascending=False)
      .head(10))

best_gb_model = GradientBoostingClassifier(
    learning_rate=0.1,
    max_depth=3,
    min_samples_split=3,
    n_estimators=150,
    subsample=0.9,
    random_state=42
)

# Fit the model on the training data (assuming X_train and y_train are defined)
best_gb_model.fit(X_train, y_train)

# Predict on the test set using the trained model
y_pred = best_gb_model.predict(X_test)

# Evaluate the model
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Save the model using joblib
joblib.dump(best_gb_model, 'gradient_boosting_model_best_params.pkl')
print("Model saved successfully with the best parameters.")

import joblib

# Load the saved models from the Kaggle working directory
rf_model = joblib.load('/kaggle/working/random_forest_model.pkl')


import xgboost as xgb

# Load the XGBoost model from the .json file
xgb_model = xgb.Booster()
xgb_model.load_model('/kaggle/working/xgboost_model.json')



gb_model = joblib.load('/kaggle/working/gradient_boosting_model_best_params.pkl')

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import cross_val_score
import numpy as np
from sklearn.metrics import accuracy_score
import joblib

# Load the saved models
rf_model = joblib.load('/kaggle/working/random_forest_model.pkl')

# Load XGBoost model using xgboost (correct way)
xgb_model = xgb.Booster()
xgb_model.load_model('/kaggle/working/xgboost_model.json')

# Load Gradient Boosting model using joblib
gb_model = joblib.load('/kaggle/working/gradient_boosting_model_best_params.pkl')

X_train = df_train.drop('Churn', axis=1)  # Drop the target column
y_train = df_train['Churn']  # Target variable

# Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

# XGBoost (using DMatrix)
xgb_model = xgb.XGBClassifier()
xgb_model.fit(X_train, y_train)

rf_predictions = rf_model.predict(X_test)
xgb_predictions = xgb_model.predict(X_test)
gb_predictions = gb_model.predict(X_test)

from sklearn.metrics import classification_report

# Assuming df_test has the actual target values for evaluation
y_test = df_test['Churn']

# Print classification report for each model
print("Random Forest Classification Report:")
print(classification_report(y_test, rf_predictions))
print("***"*30)

print("XGBoost Classification Report:")
print(classification_report(y_test, xgb_predictions))
print("***"*30)
print("Gradient Boosting Classification Report:")
print(classification_report(y_test, gb_predictions))

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# Plot confusion matrices
def plot_confusion_matrix(model_name, y_true, y_pred, ax):
    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, ax=ax)
    ax.title.set_text(f'{model_name} Confusion Matrix')

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
plot_confusion_matrix("Random Forest", y_test, rf_predictions, axes[0])
plot_confusion_matrix("XGBoost", y_test, xgb_predictions, axes[1])
plot_confusion_matrix("Gradient Boosting", y_test, gb_predictions, axes[2])
plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score
import pandas as pd

# Remove charge columns from test data
charge_columns = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']

# Prepare data
X_train = df_train.drop('Churn', axis=1)  # Features
y_train = df_train['Churn']  # Target

X_test = df_test.drop(['Churn'] + charge_columns, axis=1)  # Features
y_test = df_test['Churn']  # Target

# Train Random Forest model
rf_model = RandomForestClassifier(
    bootstrap=False,
    max_depth=None,
    max_features='sqrt',
    min_samples_leaf=1,
    min_samples_split=5,
    n_estimators=150,
    random_state=42
)
rf_model.fit(X_train, y_train)

# Train XGBoost model
xgb_model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    n_estimators=100,
    max_depth=10,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=3,
    random_state=42
)
xgb_model.fit(X_train, y_train)

# Train Gradient Boosting model
gb_model = GradientBoostingClassifier(
    learning_rate=0.1,
    max_depth=3,
    min_samples_split=3,
    n_estimators=150,
    subsample=0.9,
    random_state=42
)
gb_model.fit(X_train, y_train)

# Generate predictions
rf_predictions = rf_model.predict(X_test)
xgb_predictions = xgb_model.predict(X_test)
gb_predictions = gb_model.predict(X_test)

def print_model_summary(model_name, y_true, y_pred):
    """Print comprehensive summary for a model"""
    print(f"\n{model_name} Performance Summary:")
    print("-" * 50)

    # Calculate metrics
    accuracy = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)

    # Print main metrics
    print(f"Accuracy: {accuracy:.3f}")
    print(f"F1-Score: {f1:.3f}")
    print(f"Precision: {precision:.3f}")
    print(f"Recall: {recall:.3f}")

    # Print detailed classification report
    print("\nDetailed Classification Report:")
    print(classification_report(y_true, y_pred))

# Print summaries for each model
print_model_summary("Random Forest", y_test, rf_predictions)
print_model_summary("XGBoost", y_test, xgb_predictions)
print_model_summary("Gradient Boosting", y_test, gb_predictions)

# Create comparison DataFrame
models_comparison = pd.DataFrame({
    'Model': ['Random Forest', 'XGBoost', 'Gradient Boosting'],
    'Accuracy': [accuracy_score(y_test, rf_predictions),
                accuracy_score(y_test, xgb_predictions),
                accuracy_score(y_test, gb_predictions)],
    'F1-Score': [f1_score(y_test, rf_predictions),
                 f1_score(y_test, xgb_predictions),
                 f1_score(y_test, gb_predictions)],
    'Precision': [precision_score(y_test, rf_predictions),
                  precision_score(y_test, xgb_predictions),
                  precision_score(y_test, gb_predictions)],
    'Recall': [recall_score(y_test, rf_predictions),
               recall_score(y_test, xgb_predictions),
               recall_score(y_test, gb_predictions)]
})

print("\nModel Comparison Summary:")
print("-" * 50)
print(models_comparison.round(3).to_string(index=False))

# Find best model based on F1-score
best_model_row = models_comparison.loc[models_comparison['F1-Score'].idxmax()]
print("\nBest Performing Model:")
print("-" * 50)
print(f"Model: {best_model_row['Model']}")
print(f"Accuracy: {best_model_row['Accuracy']:.3f}")
print(f"F1-Score: {best_model_row['F1-Score']:.3f}")
print(f"Precision: {best_model_row['Precision']:.3f}")
print(f"Recall: {best_model_row['Recall']:.3f}")

# Print model parameters
print("\nBest Model Parameters:")
print("-" * 50)
if best_model_row['Model'] == 'Random Forest':
    print("Random Forest Parameters:")
    print("bootstrap=False")
    print("max_depth=None")
    print("max_features='sqrt'")
    print("min_samples_leaf=1")
    print("min_samples_split=5")
    print("n_estimators=150")
elif best_model_row['Model'] == 'XGBoost':
    print("XGBoost Parameters:")
    print("n_estimators=100")
    print("max_depth=10")
    print("learning_rate=0.05")
    print("subsample=0.8")
    print("colsample_bytree=0.8")
    print("scale_pos_weight=3")
else:
    print("Gradient Boosting Parameters:")
    print("learning_rate=0.1")
    print("max_depth=3")
    print("min_samples_split=3")
    print("n_estimators=150")
    print("subsample=0.9")

# prompt: save the best model

import joblib

# Assuming 'best_model' is the variable holding your best model
# Replace 'best_model' and 'best_model.pkl' with your actual variable and filename

# Assuming best_model is supposed to be the model with the highest F1-Score
# Let's retrieve it from models_comparison based on F1-score
# (Note: models_comparison should be defined in the previous code)
best_model_row = models_comparison.loc[models_comparison['F1-Score'].idxmax()]
best_model_name = best_model_row['Model']

if best_model_name == 'Random Forest':
    best_model = rf_model
elif best_model_name == 'XGBoost':
    best_model = xgb_model
else:  # Assuming 'Gradient Boosting'
    best_model = gb_model

joblib.dump(best_model, 'best_model.pkl')
print("Best model saved successfully.")